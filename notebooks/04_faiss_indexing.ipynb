{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "49f9ae13-bf4c-44da-a406-e9fd8f378da1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embeddings shape: (43916, 2048)\n",
      "Data type: float32\n",
      "Memory: 359.8 MB\n",
      "\n",
      "After float32 conversion:\n",
      "  Data type: float32\n",
      "  Memory: 359.8 MB\n",
      "\n",
      "After L2 normalization:\n",
      "  Min norm: 1.000000\n",
      "  Max norm: 1.000000\n",
      "  (Should both be ~1.0)\n",
      "\n",
      "Ready for FAISS:\n",
      "  43,916 vectors\n",
      "  2048 dimensions each\n",
      "  359.8 MB total\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# CELL 1: Load Embeddings and Prepare for FAISS\n",
    "# ============================================================\n",
    "import numpy as np\n",
    "import faiss\n",
    "import time\n",
    "import pandas as pd\n",
    "\n",
    "# Paths\n",
    "EMBED_DIR = '../data/embeddings'\n",
    "DATA_DIR = '../data/processed'\n",
    "IMAGE_DIR = '../data/raw/images'\n",
    "\n",
    "# Load fine-tuned embeddings (these are our best ones)\n",
    "embeddings = np.load(f'{EMBED_DIR}/finetuned_embeddings.npy')\n",
    "ids = np.load(f'{EMBED_DIR}/finetuned_ids.npy')\n",
    "\n",
    "# Load metadata for displaying results\n",
    "df = pd.read_csv(f'{DATA_DIR}/filtered_styles.csv')\n",
    "\n",
    "print(f\"Embeddings shape: {embeddings.shape}\")\n",
    "print(f\"Data type: {embeddings.dtype}\")\n",
    "print(f\"Memory: {embeddings.nbytes / 1e6:.1f} MB\")\n",
    "\n",
    "# --- STEP 1: Convert to float32 ---\n",
    "# FAISS requires float32 (not float64)\n",
    "embeddings = embeddings.astype(np.float32)\n",
    "print(f\"\\nAfter float32 conversion:\")\n",
    "print(f\"  Data type: {embeddings.dtype}\")\n",
    "print(f\"  Memory: {embeddings.nbytes / 1e6:.1f} MB\")\n",
    "\n",
    "# --- STEP 2: L2 Normalize ---\n",
    "# This makes L2 distance equivalent to cosine similarity\n",
    "faiss.normalize_L2(embeddings)\n",
    "\n",
    "# Verify normalization: each vector should have length = 1.0\n",
    "norms = np.linalg.norm(embeddings, axis=1)\n",
    "print(f\"\\nAfter L2 normalization:\")\n",
    "print(f\"  Min norm: {norms.min():.6f}\")\n",
    "print(f\"  Max norm: {norms.max():.6f}\")\n",
    "print(f\"  (Should both be ~1.0)\")\n",
    "\n",
    "# --- STEP 3: Key dimensions ---\n",
    "n_vectors, dimension = embeddings.shape\n",
    "print(f\"\\nReady for FAISS:\")\n",
    "print(f\"  {n_vectors:,} vectors\")\n",
    "print(f\"  {dimension} dimensions each\")\n",
    "print(f\"  {embeddings.nbytes / 1e6:.1f} MB total\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b4080531-043e-4b75-9766-f2c073efc569",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building Flat Index (exact search)...\n",
      "  Build time: 20.7 ms\n",
      "  Vectors in index: 43,916\n",
      "\n",
      "  Single query time: 7.38 ms\n",
      "\n",
      "Query: ID=15970, Type=Shirts\n",
      "Rank   ID         Type                 L2 Distance  Cosine Sim\n",
      "------------------------------------------------------------\n",
      "  1    15970      Shirts               0.0000       1.0000     ✓\n",
      "  2    31627      Shirts               0.0060       0.9970     ✓\n",
      "  3    8741       Shirts               0.0063       0.9968     ✓\n",
      "  4    9646       Shirts               0.0063       0.9968     ✓\n",
      "  5    28806      Shirts               0.0073       0.9963     ✓\n",
      "\n",
      "Benchmarking 100 queries...\n",
      "  Total time for 100 queries: 47.2 ms\n",
      "  Average per query: 0.47 ms\n",
      "  Queries per second: 2117\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# CELL 2: Flat Index — Exact Nearest Neighbor Search\n",
    "# ============================================================\n",
    "import faiss\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "# --- STEP 1: Build the index ---\n",
    "print(\"Building Flat Index (exact search)...\")\n",
    "start = time.time()\n",
    "\n",
    "flat_index = faiss.IndexFlatL2(dimension)  # dimension = 2048\n",
    "flat_index.add(embeddings)                 # add all vectors\n",
    "\n",
    "build_time = time.time() - start\n",
    "print(f\"  Build time: {build_time*1000:.1f} ms\")\n",
    "print(f\"  Vectors in index: {flat_index.ntotal:,}\")\n",
    "\n",
    "# --- STEP 2: Test single query ---\n",
    "# Pick a random image as query\n",
    "query_id = ids[0]\n",
    "query_vector = embeddings[0].reshape(1, -1)  # FAISS needs shape (1, 2048)\n",
    "\n",
    "start = time.time()\n",
    "distances, indices = flat_index.search(query_vector, k=5)\n",
    "search_time = time.time() - start\n",
    "\n",
    "print(f\"\\n  Single query time: {search_time*1000:.2f} ms\")\n",
    "\n",
    "# Show results\n",
    "query_type = df[df['id'] == query_id]['articleType'].values[0]\n",
    "print(f\"\\nQuery: ID={query_id}, Type={query_type}\")\n",
    "print(f\"{'Rank':<6} {'ID':<10} {'Type':<20} {'L2 Distance':<12} {'Cosine Sim':<10}\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "for rank in range(5):\n",
    "    result_idx = indices[0][rank]\n",
    "    result_id = ids[result_idx]\n",
    "    result_type = df[df['id'] == result_id]['articleType'].values[0]\n",
    "    l2_dist = distances[0][rank]\n",
    "    cos_sim = 1 - l2_dist / 2  # convert L2² back to cosine similarity\n",
    "    match = \"✓\" if result_type == query_type else \"✗\"\n",
    "    print(f\"  {rank+1:<4} {result_id:<10} {result_type:<20} {l2_dist:<12.4f} {cos_sim:<10.4f} {match}\")\n",
    "\n",
    "# --- STEP 3: Benchmark — run 100 queries ---\n",
    "print(f\"\\nBenchmarking 100 queries...\")\n",
    "query_vectors = embeddings[:100]  # first 100 as queries\n",
    "\n",
    "start = time.time()\n",
    "distances, indices = flat_index.search(query_vectors, k=5)\n",
    "total_time = time.time() - start\n",
    "\n",
    "print(f\"  Total time for 100 queries: {total_time*1000:.1f} ms\")\n",
    "print(f\"  Average per query: {total_time*10:.2f} ms\")\n",
    "print(f\"  Queries per second: {100/total_time:.0f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6b226e09-7d17-43c7-85f4-4d4c776bbe29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training IVF Index (running K-means clustering)...\n",
      "  Train time: 0.37 seconds\n",
      "  Add time: 79.4 ms\n",
      "  Vectors in index: 43,916\n",
      "\n",
      "Benchmarking IVF with different nprobe values:\n",
      "nprobe     Time (ms)    Queries/sec    Recall@5  \n",
      "------------------------------------------------\n",
      "1          7.9          12588          77.20%    \n",
      "2          14.2         7031           92.80%    \n",
      "5          31.8         3144           99.00%    \n",
      "10         63.4         1578           100.00%   \n",
      "20         122.7        815            100.00%   \n",
      "50         319.8        313            100.00%   \n",
      "100        530.6        188            100.00%   \n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# CELL 3: IVF Index — Clustered Nearest Neighbor Search\n",
    "# ============================================================\n",
    "import faiss\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "# --- STEP 1: Create IVF Index ---\n",
    "nlist = 100  # number of clusters\n",
    "\n",
    "# IVF needs a \"quantizer\" — the index used to find nearest cluster\n",
    "quantizer = faiss.IndexFlatL2(dimension)  # exact search over 100 centroids\n",
    "\n",
    "# Create the IVF index\n",
    "ivf_index = faiss.IndexIVFFlat(quantizer, dimension, nlist)\n",
    "\n",
    "# --- STEP 2: Train the index (run K-means) ---\n",
    "print(\"Training IVF Index (running K-means clustering)...\")\n",
    "start = time.time()\n",
    "ivf_index.train(embeddings)  # learns the 100 cluster centroids\n",
    "train_time = time.time() - start\n",
    "print(f\"  Train time: {train_time:.2f} seconds\")\n",
    "\n",
    "# --- STEP 3: Add vectors to the index ---\n",
    "start = time.time()\n",
    "ivf_index.add(embeddings)\n",
    "add_time = time.time() - start\n",
    "print(f\"  Add time: {add_time*1000:.1f} ms\")\n",
    "print(f\"  Vectors in index: {ivf_index.ntotal:,}\")\n",
    "\n",
    "# --- STEP 4: Test with different nprobe values ---\n",
    "query_vectors = embeddings[:100]  # 100 test queries\n",
    "\n",
    "# Get ground truth from Flat Index\n",
    "_, true_neighbors = flat_index.search(query_vectors, k=5)\n",
    "\n",
    "print(f\"\\nBenchmarking IVF with different nprobe values:\")\n",
    "print(f\"{'nprobe':<10} {'Time (ms)':<12} {'Queries/sec':<14} {'Recall@5':<10}\")\n",
    "print(\"-\" * 48)\n",
    "\n",
    "for nprobe in [1, 2, 5, 10, 20, 50, 100]:\n",
    "    ivf_index.nprobe = nprobe\n",
    "    \n",
    "    # Speed test\n",
    "    start = time.time()\n",
    "    distances, indices = ivf_index.search(query_vectors, k=5)\n",
    "    elapsed = time.time() - start\n",
    "    \n",
    "    # Accuracy test: how many true neighbors did we find?\n",
    "    recall = 0\n",
    "    for i in range(100):\n",
    "        true_set = set(true_neighbors[i])\n",
    "        found_set = set(indices[i])\n",
    "        recall += len(true_set & found_set) / 5\n",
    "    recall /= 100  # average over 100 queries\n",
    "    \n",
    "    qps = 100 / elapsed\n",
    "    print(f\"{nprobe:<10} {elapsed*1000:<12.1f} {qps:<14.0f} {recall:<10.2%}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "206edf2d-b714-4260-8989-b1dbbbd62855",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building IVF+PQ Index (clustered + compressed)...\n",
      "  Train time: 15.36 seconds\n",
      "  Add time: 956.6 ms\n",
      "\n",
      "  Memory comparison:\n",
      "    Flat Index:   359.8 MB\n",
      "    IVF+PQ Index: 2.8 MB\n",
      "    Compression:  128x smaller!\n",
      "\n",
      "Benchmarking IVF+PQ with different nprobe values:\n",
      "nprobe     Time (ms)    Queries/sec    Recall@5  \n",
      "------------------------------------------------\n",
      "1          1.9          53911          56.60%    \n",
      "2          2.1          46927          62.00%    \n",
      "5          2.6          38607          62.60%    \n",
      "10         3.6          27979          62.60%    \n",
      "20         5.6          17706          62.60%    \n",
      "50         12.4         8094           62.60%    \n",
      "100        20.4         4903           62.60%    \n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# CELL 4: IVF + PQ Index — Compressed Nearest Neighbor Search\n",
    "# ============================================================\n",
    "import faiss\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "# --- Parameters ---\n",
    "nlist = 100   # number of clusters (same as IVF)\n",
    "m = 64        # number of sub-vectors (2048 / 64 = 32 dims each)\n",
    "nbits = 8     # bits per code (8 bits = 256 possible codes per sub-vector)\n",
    "\n",
    "# --- STEP 1: Create IVF+PQ Index ---\n",
    "print(\"Building IVF+PQ Index (clustered + compressed)...\")\n",
    "quantizer = faiss.IndexFlatL2(dimension)\n",
    "ivfpq_index = faiss.IndexIVFPQ(quantizer, dimension, nlist, m, nbits)\n",
    "\n",
    "# --- STEP 2: Train (learns clusters AND codebooks) ---\n",
    "start = time.time()\n",
    "ivfpq_index.train(embeddings)\n",
    "train_time = time.time() - start\n",
    "print(f\"  Train time: {train_time:.2f} seconds\")\n",
    "\n",
    "# --- STEP 3: Add vectors ---\n",
    "start = time.time()\n",
    "ivfpq_index.add(embeddings)\n",
    "add_time = time.time() - start\n",
    "print(f\"  Add time: {add_time*1000:.1f} ms\")\n",
    "\n",
    "# --- STEP 4: Compare memory usage ---\n",
    "flat_memory = embeddings.nbytes\n",
    "ivfpq_memory = ivfpq_index.ntotal * m  # each vector = m bytes\n",
    "\n",
    "print(f\"\\n  Memory comparison:\")\n",
    "print(f\"    Flat Index:   {flat_memory / 1e6:.1f} MB\")\n",
    "print(f\"    IVF+PQ Index: {ivfpq_memory / 1e6:.1f} MB\")\n",
    "print(f\"    Compression:  {flat_memory / ivfpq_memory:.0f}x smaller!\")\n",
    "\n",
    "# --- STEP 5: Benchmark with different nprobe values ---\n",
    "query_vectors = embeddings[:100]\n",
    "_, true_neighbors = flat_index.search(query_vectors, k=5)\n",
    "\n",
    "print(f\"\\nBenchmarking IVF+PQ with different nprobe values:\")\n",
    "print(f\"{'nprobe':<10} {'Time (ms)':<12} {'Queries/sec':<14} {'Recall@5':<10}\")\n",
    "print(\"-\" * 48)\n",
    "\n",
    "for nprobe in [1, 2, 5, 10, 20, 50, 100]:\n",
    "    ivfpq_index.nprobe = nprobe\n",
    "    \n",
    "    start = time.time()\n",
    "    distances, indices = ivfpq_index.search(query_vectors, k=5)\n",
    "    elapsed = time.time() - start\n",
    "    \n",
    "    recall = 0\n",
    "    for i in range(100):\n",
    "        true_set = set(true_neighbors[i])\n",
    "        found_set = set(indices[i])\n",
    "        recall += len(true_set & found_set) / 5\n",
    "    recall /= 100\n",
    "    \n",
    "    qps = 100 / elapsed\n",
    "    print(f\"{nprobe:<10} {elapsed*1000:<12.1f} {qps:<14.0f} {recall:<10.2%}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ecf0ed73-c216-4cb6-9177-86acba4b7074",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building IVF+PQ Index (m=128, better accuracy)...\n",
      "  Train time: 29.46 seconds\n",
      "  Add time: 2830.0 ms\n",
      "\n",
      "  Memory: 5.6 MB\n",
      "  Compression: 64x smaller than Flat\n",
      "\n",
      "Benchmarking IVF+PQ (m=128):\n",
      "nprobe     Time (ms)    Queries/sec    Recall@5  \n",
      "------------------------------------------------\n",
      "1          3.0          32799          62.40%    \n",
      "2          3.4          29335          68.20%    \n",
      "5          4.7          21441          70.20%    \n",
      "10         6.8          14661          70.60%    \n",
      "20         12.0         8351           70.60%    \n",
      "50         31.4         3187           70.60%    \n",
      "100        46.9         2132           70.60%    \n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# CELL 4b: IVF+PQ with More Sub-vectors (faster than OPQ)\n",
    "# ============================================================\n",
    "import faiss\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "# --- Use more sub-vectors for better accuracy ---\n",
    "nlist = 100\n",
    "m = 128       # 128 sub-vectors instead of 64 (each piece = 16 dims)\n",
    "nbits = 8     # 8 bits per code\n",
    "\n",
    "print(\"Building IVF+PQ Index (m=128, better accuracy)...\")\n",
    "quantizer = faiss.IndexFlatL2(dimension)\n",
    "ivfpq2_index = faiss.IndexIVFPQ(quantizer, dimension, nlist, m, nbits)\n",
    "\n",
    "# Train\n",
    "start = time.time()\n",
    "ivfpq2_index.train(embeddings)\n",
    "train_time = time.time() - start\n",
    "print(f\"  Train time: {train_time:.2f} seconds\")\n",
    "\n",
    "# Add vectors\n",
    "start = time.time()\n",
    "ivfpq2_index.add(embeddings)\n",
    "add_time = time.time() - start\n",
    "print(f\"  Add time: {add_time*1000:.1f} ms\")\n",
    "\n",
    "# Memory\n",
    "pq2_memory = ivfpq2_index.ntotal * m\n",
    "print(f\"\\n  Memory: {pq2_memory / 1e6:.1f} MB\")\n",
    "print(f\"  Compression: {embeddings.nbytes / pq2_memory:.0f}x smaller than Flat\")\n",
    "\n",
    "# Benchmark\n",
    "query_vectors = embeddings[:100]\n",
    "_, true_neighbors = flat_index.search(query_vectors, k=5)\n",
    "\n",
    "print(f\"\\nBenchmarking IVF+PQ (m=128):\")\n",
    "print(f\"{'nprobe':<10} {'Time (ms)':<12} {'Queries/sec':<14} {'Recall@5':<10}\")\n",
    "print(\"-\" * 48)\n",
    "\n",
    "for nprobe in [1, 2, 5, 10, 20, 50, 100]:\n",
    "    ivfpq2_index.nprobe = nprobe\n",
    "    \n",
    "    start = time.time()\n",
    "    distances, indices = ivfpq2_index.search(query_vectors, k=5)\n",
    "    elapsed = time.time() - start\n",
    "    \n",
    "    recall = 0\n",
    "    for i in range(100):\n",
    "        true_set = set(true_neighbors[i])\n",
    "        found_set = set(indices[i])\n",
    "        recall += len(true_set & found_set) / 5\n",
    "    recall /= 100\n",
    "    \n",
    "    qps = 100 / elapsed\n",
    "    print(f\"{nprobe:<10} {elapsed*1000:<12.1f} {qps:<14.0f} {recall:<10.2%}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "77b6dc7e-4260-4a7b-82d1-c3993532ed50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===========================================================================\n",
      "FINAL COMPARISON: All FAISS Index Types\n",
      "===========================================================================\n",
      "Index                Memory       nprobe   Speed (q/s)    Recall@5  \n",
      "---------------------------------------------------------------------------\n",
      "Flat (exact)         359.8 MB     n/a      2183           100.00%   \n",
      "IVF (nprobe=5)       359.8 MB     5        1734           99.00%    \n",
      "IVF (nprobe=10)      359.8 MB     10       1581           100.00%   \n",
      "IVF+PQ (m=64)        2.8 MB       10       15967          62.60%    \n",
      "IVF+PQ (m=128)       5.6 MB       10       11869          70.60%    \n",
      "---------------------------------------------------------------------------\n",
      "\n",
      "RECOMMENDATION:\n",
      "  For our dataset (44K vectors, 360 MB):\n",
      "    → Use IVF with nprobe=10 (100% recall, fast enough)\n",
      "    → Flat Index also fine (exact results, simple to maintain)\n",
      "\n",
      "  For production at scale (1M+ vectors):\n",
      "    → Use IVF+PQ for memory savings\n",
      "    → Accept ~70% recall trade-off OR use re-ranking to recover accuracy\n",
      "\n",
      "  For this project:\n",
      "    → We'll use IVF (nprobe=10) as our production index\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# CELL 5: Final Comparison — All Index Types\n",
    "# ============================================================\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "query_vectors = embeddings[:100]\n",
    "_, true_neighbors = flat_index.search(query_vectors, k=5)\n",
    "\n",
    "print(\"=\" * 75)\n",
    "print(\"FINAL COMPARISON: All FAISS Index Types\")\n",
    "print(\"=\" * 75)\n",
    "print(f\"{'Index':<20} {'Memory':<12} {'nprobe':<8} {'Speed (q/s)':<14} {'Recall@5':<10}\")\n",
    "print(\"-\" * 75)\n",
    "\n",
    "# 1. Flat Index\n",
    "start = time.time()\n",
    "flat_index.search(query_vectors, k=5)\n",
    "elapsed = time.time() - start\n",
    "print(f\"{'Flat (exact)':<20} {'359.8 MB':<12} {'n/a':<8} {100/elapsed:<14.0f} {'100.00%':<10}\")\n",
    "\n",
    "# 2. IVF (nprobe=5)\n",
    "ivf_index.nprobe = 5\n",
    "start = time.time()\n",
    "d, idx = ivf_index.search(query_vectors, k=5)\n",
    "elapsed = time.time() - start\n",
    "recall = sum(len(set(true_neighbors[i]) & set(idx[i]))/5 for i in range(100)) / 100\n",
    "print(f\"{'IVF (nprobe=5)':<20} {'359.8 MB':<12} {'5':<8} {100/elapsed:<14.0f} {recall:<10.2%}\")\n",
    "\n",
    "# 3. IVF (nprobe=10)\n",
    "ivf_index.nprobe = 10\n",
    "start = time.time()\n",
    "d, idx = ivf_index.search(query_vectors, k=5)\n",
    "elapsed = time.time() - start\n",
    "recall = sum(len(set(true_neighbors[i]) & set(idx[i]))/5 for i in range(100)) / 100\n",
    "print(f\"{'IVF (nprobe=10)':<20} {'359.8 MB':<12} {'10':<8} {100/elapsed:<14.0f} {recall:<10.2%}\")\n",
    "\n",
    "# 4. IVF+PQ (m=64)\n",
    "ivfpq_index.nprobe = 10\n",
    "start = time.time()\n",
    "d, idx = ivfpq_index.search(query_vectors, k=5)\n",
    "elapsed = time.time() - start\n",
    "recall = sum(len(set(true_neighbors[i]) & set(idx[i]))/5 for i in range(100)) / 100\n",
    "print(f\"{'IVF+PQ (m=64)':<20} {'2.8 MB':<12} {'10':<8} {100/elapsed:<14.0f} {recall:<10.2%}\")\n",
    "\n",
    "# 5. IVF+PQ (m=128)\n",
    "ivfpq2_index.nprobe = 10\n",
    "start = time.time()\n",
    "d, idx = ivfpq2_index.search(query_vectors, k=5)\n",
    "elapsed = time.time() - start\n",
    "recall = sum(len(set(true_neighbors[i]) & set(idx[i]))/5 for i in range(100)) / 100\n",
    "print(f\"{'IVF+PQ (m=128)':<20} {'5.6 MB':<12} {'10':<8} {100/elapsed:<14.0f} {recall:<10.2%}\")\n",
    "\n",
    "print(\"-\" * 75)\n",
    "\n",
    "print(\"\"\"\n",
    "RECOMMENDATION:\n",
    "  For our dataset (44K vectors, 360 MB):\n",
    "    → Use IVF with nprobe=10 (100% recall, fast enough)\n",
    "    → Flat Index also fine (exact results, simple to maintain)\n",
    "\n",
    "  For production at scale (1M+ vectors):\n",
    "    → Use IVF+PQ for memory savings\n",
    "    → Accept ~70% recall trade-off OR use re-ranking to recover accuracy\n",
    "\n",
    "  For this project:\n",
    "    → We'll use IVF (nprobe=10) as our production index\n",
    "\"\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1551ac1f-166d-459e-b43b-35f73d4dd03b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: flat_index.faiss (359.8 MB)\n",
      "Saved: ivf_index.faiss (360.9 MB)\n",
      "\n",
      "Verification:\n",
      "  Loaded flat_index: 43,916 vectors\n",
      "  Test search: top 3 IDs = [np.int64(15970), np.int64(31627), np.int64(8741)]\n",
      "  Distances: [0.         0.00600655 0.00633012]\n",
      "\n",
      "✅ Indexes saved and verified!\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# CELL 6: Save FAISS Indexes to Disk\n",
    "# ============================================================\n",
    "import faiss\n",
    "import os\n",
    "\n",
    "INDEX_DIR = '../indexing'\n",
    "os.makedirs(INDEX_DIR, exist_ok=True)\n",
    "\n",
    "# Save Flat Index\n",
    "faiss.write_index(flat_index, f'{INDEX_DIR}/flat_index.faiss')\n",
    "flat_size = os.path.getsize(f'{INDEX_DIR}/flat_index.faiss')\n",
    "print(f\"Saved: flat_index.faiss ({flat_size/1e6:.1f} MB)\")\n",
    "\n",
    "# Save IVF Index\n",
    "faiss.write_index(ivf_index, f'{INDEX_DIR}/ivf_index.faiss')\n",
    "ivf_size = os.path.getsize(f'{INDEX_DIR}/ivf_index.faiss')\n",
    "print(f\"Saved: ivf_index.faiss ({ivf_size/1e6:.1f} MB)\")\n",
    "\n",
    "# Verify by loading back\n",
    "test_index = faiss.read_index(f'{INDEX_DIR}/flat_index.faiss')\n",
    "print(f\"\\nVerification:\")\n",
    "print(f\"  Loaded flat_index: {test_index.ntotal:,} vectors\")\n",
    "\n",
    "# Test search on loaded index\n",
    "query = embeddings[0].reshape(1, -1)\n",
    "distances, indices = test_index.search(query, k=3)\n",
    "print(f\"  Test search: top 3 IDs = {[ids[i] for i in indices[0]]}\")\n",
    "print(f\"  Distances: {distances[0]}\")\n",
    "print(f\"\\n✅ Indexes saved and verified!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2de323a3-0881-4507-90e5-1174188b4745",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
